{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a67452bc-52fe-411b-91ae-af5a133a0136",
   "metadata": {},
   "source": [
    "## Expanding Base Dataset\n",
    "\n",
    "**Author:** Shaun Khoo  \n",
    "**Date:** 18 Oct 2021  \n",
    "**Context:** There are serious data quality issues after investigating the original training data. Over 70% of the data have less than 10 samples (50% of the data has no examples) in the full training set, which will result in a poorer model that is unable to predict most of the available SSOCs.  \n",
    "**Objective:** Instead of relying on the original training data, we seek to construct a higher-quality but smaller-sized new training dataset. This will be assembled by finding the most relevant job postings for each SSOC, and ensuring we have at least 10 samples for each SSOC."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05664d72-7fff-4cc2-8118-5b8661105cb6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### A) Setting up\n",
    "\n",
    "Importing the libraries and data here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "112dd83a-43ed-4706-8891-b9bd1dff92fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63e12ef2-f414-4811-86f1-89af8bc3ea0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "import re\n",
    "import json\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "786f6cc7-3092-43ec-a206-5fe407c88d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "SSOC_2020 = pd.read_csv('Data/Processed/Training/train-aws/SSOC_2020.csv')\n",
    "data = pd.read_csv('Data/Processed/Training/train-aws/train_full.csv')\n",
    "extra_info = pd.read_csv('Data/Archive/MCF_Training_Set_Full.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d8618a-2a79-43e2-b512-7c30510ef51b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### B) Checking job titles\n",
    "\n",
    "For the first step, we import the detailed definitions for SSOC 2020, and use the job titles to search for an exact match on the MCF job posting. We also use the \"Examples of Job Classified Elsewhere\" separately to enable a wider search and prevent misclassification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6bc8a5a-d2a5-430f-8759-abc211bcbef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\shaun\\pycharmprojects\\ssoc-autocoder\\venv\\lib\\site-packages\\openpyxl\\worksheet\\header_footer.py:48: UserWarning: Cannot parse header or footer so it will be ignored\n",
      "  warn(\"\"\"Cannot parse header or footer so it will be ignored\"\"\")\n"
     ]
    }
   ],
   "source": [
    "detailed_definitions_raw = pd.read_excel('Data/Raw/SSOC2020 Detailed Definitions.xlsx', skiprows = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e8ac272-96bd-40e5-ba77-f10267e27830",
   "metadata": {},
   "outputs": [],
   "source": [
    "detailed_definitions = detailed_definitions_raw[(~detailed_definitions_raw['SSOC 2020'].astype('str').str.contains('X')) &\n",
    "                                                (detailed_definitions_raw['SSOC 2020'].astype('str').apply(len) >= 5)].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b6485a-85d3-433b-898a-fc32a47e71f1",
   "metadata": {},
   "source": [
    "Clean both the relevant and incorrect job titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20168fc5-2735-47b4-b5f7-685cc4be4b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shaun\\AppData\\Local\\Temp/ipykernel_11880/2208409054.py:12: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  detailed_definitions['Relevant_Job_Titles_Cleaned'] = detailed_definitions['Relevant_Job_Titles_Cleaned'].str.replace(k, v)\n",
      "C:\\Users\\shaun\\AppData\\Local\\Temp/ipykernel_11880/2208409054.py:13: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  detailed_definitions['Incorrect_Job_Titles_Cleaned'] = detailed_definitions['Incorrect_Job_Titles_Cleaned'].str.replace(k, v)\n"
     ]
    }
   ],
   "source": [
    "to_replace = {\n",
    "    '‚Ä¢': '',\n",
    "    '\\n': '.',\n",
    "    '<Blank>': '',\n",
    "    \"\\([A-Za-z0-9 /.,*&'-]+\\)\": ''\n",
    "}\n",
    "\n",
    "detailed_definitions['Relevant_Job_Titles_Cleaned'] = detailed_definitions['Examples of Job Classified Under this Code']\n",
    "detailed_definitions['Incorrect_Job_Titles_Cleaned'] = detailed_definitions['Examples of Job Classified Elsewhere']\n",
    "\n",
    "for k, v in to_replace.items():\n",
    "    detailed_definitions['Relevant_Job_Titles_Cleaned'] = detailed_definitions['Relevant_Job_Titles_Cleaned'].str.replace(k, v)\n",
    "    detailed_definitions['Incorrect_Job_Titles_Cleaned'] = detailed_definitions['Incorrect_Job_Titles_Cleaned'].str.replace(k, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdab2ec7-f543-46a8-9890-6ff42be184a5",
   "metadata": {},
   "source": [
    "Use both data points to create a dictionary that helps us to map the job titles to the SSOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1da5641d-4149-4e5a-a8a1-9d5064f9553c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssoc_job_titles = {}\n",
    "for i, row in detailed_definitions.iterrows():\n",
    "    titles = [row['SSOC 2020 Title']]\n",
    "    titles.extend([title.strip() for title in row['Relevant_Job_Titles_Cleaned'].split('.')])\n",
    "    final_titles = list(set([title.lower() for title in titles]))\n",
    "    ssoc_job_titles[row['SSOC 2020']] = final_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91ad9931-f854-487c-bf29-35c32283d1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_incorrect_job_titles(text):\n",
    "    \n",
    "    # If there are no jobs classified elsewhere, return nothing\n",
    "    if len(text) == 0:\n",
    "        return {}\n",
    "    \n",
    "    incorrect_job_titles = text.split('.')\n",
    "    output = {}\n",
    "    for entry in incorrect_job_titles:\n",
    "        \n",
    "        # Use the fact that the structure is consistent\n",
    "        ssoc = entry.split(', see')[1].strip()\n",
    "        title = entry.split(', see')[0].strip().lower()\n",
    "        if ssoc in output.keys():\n",
    "            output[ssoc].append(title)\n",
    "        else:\n",
    "            output[ssoc] = [title]\n",
    "    return output\n",
    "\n",
    "additions = detailed_definitions['Incorrect_Job_Titles_Cleaned'].apply(extract_incorrect_job_titles)\n",
    "\n",
    "# Append the new 'jobs classified elsewhere' to their relevant SSOC\n",
    "for addition in additions:\n",
    "    if len(addition.keys()) != 0:\n",
    "        for k, v in addition.items():\n",
    "            ssoc_job_titles[k].extend(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "281c3ac3-99a2-4e91-b01e-74d04d84e6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_matching_job_title(data,\n",
    "                            include,\n",
    "                            exclude,\n",
    "                            exclude_desc = []):\n",
    "    \n",
    "    output = copy.deepcopy(data)\n",
    "    output['title'] = output['title'].str.lower()\n",
    "    output['description'] = output['description'].str.lower()\n",
    "    \n",
    "    include_boolean = [False] * len(output)\n",
    "    for words in include:\n",
    "        entry_boolean = [True] * len(output)\n",
    "        \n",
    "        # This helps to clean out punctuation that trips up our functions below\n",
    "        for k,v in to_replace.items():\n",
    "            words = re.sub(k, v, words)\n",
    "            \n",
    "        for word in words.split(' '):\n",
    "            try:\n",
    "                entry_boolean = entry_boolean & output['title'].str.contains(word.lower())\n",
    "            except:\n",
    "                print(words)\n",
    "                \n",
    "        include_boolean = include_boolean | entry_boolean\n",
    "    \n",
    "    for words in exclude:\n",
    "        for word in words.split(' '):\n",
    "            include_boolean = include_boolean & ~output['title'].str.contains(word.lower())\n",
    "    \n",
    "    for words in exclude_desc:\n",
    "        for word in words.split(' '):\n",
    "            include_boolean = include_boolean & ~output['description'].str.contains(word.lower())\n",
    "    \n",
    "    job_titles_idx = output[include_boolean.values].index.tolist()\n",
    "    return job_titles_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51458e30-d636-420c-ad93-f52590d7e68d",
   "metadata": {},
   "source": [
    "Test our function to make sure it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38a9cf69-4cd7-402a-adcc-a9a87c0c341a",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_titles_idx = find_matching_job_title(extra_info,\n",
    "                                         include = ssoc_job_titles['13430'],\n",
    "                                         exclude = ['provided'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "437851d7-a4d3-42c8-82fe-2c67840a9e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3007, 3415, 3416, 11933]\n",
      "3007: ASSISTANT DIRECTOR OF NURSING ( NURSING HOME) #SGUnitedJobs\n",
      "3415: ASSISTANT DIRECTOR OF NURSING ( NURSING HOME) #SGUnitedJobs\n",
      "3416: ASSISTANT DIRECTOR OF NURSING ( NURSING HOME) #SGUnitedJobs\n",
      "11933: ASSISTANT DIRECTOR OF NURSING ( NURSING HOME) #SGUnitedJobs\n"
     ]
    }
   ],
   "source": [
    "print(job_titles_idx)\n",
    "for i, title in extra_info.loc[job_titles_idx, 'title'].iteritems():\n",
    "    print(f\"{i}: {title}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc612f2-e0c0-4b7b-b6f2-6c52c4867fb9",
   "metadata": {},
   "source": [
    "Now we run it for the entire group of SSOCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4893ca0-10cc-46a3-8a7a-b70f89e9e81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = {}\n",
    "for ssoc in ssoc_job_titles.keys():\n",
    "    job_titles_idx = find_matching_job_title(extra_info,\n",
    "                                             include = ssoc_job_titles[ssoc],\n",
    "                                             exclude = ['provided'])\n",
    "    output[ssoc] = job_titles_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e65d33-30c0-4319-8880-0af6722e640d",
   "metadata": {},
   "source": [
    "How many jobs have less than 10 entries?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efdfabe-37b2-484f-ae79-7aa390c9120b",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for ssoc in output.keys():\n",
    "    if len(output[ssoc]) < 10:\n",
    "        count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30dbf2b-7abb-488c-83a6-646112e844f3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### C) Using word embeddings\n",
    "\n",
    "For the second step, we convert our current subset of MCF data into word embeddings using `spacy`'s inbuilt word embeddings. This will be used to identify similar job descriptions to the SSOC description to enable a more thorough search that is not confined only to job titles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1f6620-97e9-47b5-b814-f999a316e5e4",
   "metadata": {},
   "source": [
    "Use `spacy` to convert the words into embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0adddfbc-f328-4f7f-85b2-437a00103c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.language import Language\n",
    "nlp = spacy.load('en_core_web_lg', disable = ['tagger', 'parser', 'ner', 'lemmatizer'])\n",
    "stopwords = nlp.Defaults.stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83ee3448-2b0f-4a39-97fc-bcf7ff3c4bb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.additional_preprocessing(doc)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@Language.component(\"additional_preprocessing\")\n",
    "def additional_preprocessing(doc):\n",
    "    lemma_list = [tok for tok in doc\n",
    "                  if tok.is_alpha and tok.text.lower() not in stopwords] \n",
    "    return lemma_list\n",
    "nlp.add_pipe('additional_preprocessing', last = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a2c4dd-4466-426b-9b05-d95f41203e38",
   "metadata": {},
   "source": [
    "Run the `nlp` processing pipeline over the two corpuses and convert the job postings into vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45dbd033-b6e1-48e6-aa90-76c1f2340844",
   "metadata": {},
   "outputs": [],
   "source": [
    "SSOC_2020_nlp = list(nlp.pipe(SSOC_2020['Description']))\n",
    "data_nlp = list(nlp.pipe(data['Cleaned_Description']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7eda5ce-d32a-4a57-bab6-0535a4da84b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job posting 42841/42842...\r"
     ]
    }
   ],
   "source": [
    "target_vecs = []\n",
    "for i, desc in enumerate(data_nlp):\n",
    "    if (i % 100 == 0) or (i+1 == len(data_nlp)):\n",
    "        print(f'Job posting {i}/{len(data_nlp)}...\\r', end = '')\n",
    "    if len(desc) == 0:\n",
    "        target_vecs.append(np.array([0]*300))\n",
    "    else:\n",
    "        target_vecs.append(np.mean([token.vector for token in desc], axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d2f10ff-d8c2-4f4c-b9ab-b3823a8ee7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def identify_top_n(selected,\n",
    "                   data,\n",
    "                   extra_info,\n",
    "                   target_vecs,\n",
    "                   top_n = 15,\n",
    "                   threshold = 0.8):\n",
    "    \n",
    "    source_vec = np.array([np.mean([token.vector for token in selected], axis = 0)])\n",
    "    matrix = cosine_similarity(source_vec, target_vecs)\n",
    "    indices = np.apply_along_axis(lambda x: x.argsort()[-top_n:][::-1], axis = 1, arr = matrix)\n",
    "    above_threshold = matrix[0][indices][0] >= threshold\n",
    "    indices = [idx for idx, above in zip(indices[0], above_threshold) if above]\n",
    "    if len(indices) == 0:\n",
    "        print('None meet the threshold required.')\n",
    "    else:\n",
    "        cosine_similarity_index = 0\n",
    "        for i, row in data.loc[indices, :].iterrows():\n",
    "            print(f'Index: {i}')\n",
    "            print(f'Cosine similarity: {matrix[0][indices][cosine_similarity_index]}')\n",
    "            print(f'Predicted SSOC: {row[\"SSOC 2020\"]}')\n",
    "            print(f'Job title: {extra_info[\"title\"][i]}')\n",
    "            print(f'Description: {row[\"Cleaned_Description\"]}')\n",
    "            print('================================================================')\n",
    "            cosine_similarity_index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5aeb9fa-4761-4ad9-918c-cf88c4a1c8f5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### D) Manual tagging\n",
    "\n",
    "Use both the job titles and word embeddings to help identify the relevant job postings for each SSOC so as to improve coverage of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0ed57286-c1b7-49c1-a23b-f5f184b06dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Run this to initialise the dictionary object\n",
    "# with open('manual_tagging.json', 'r') as outfile:\n",
    "#     manual_tagging = json.load(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1752,
   "id": "ea989783-cba3-4809-a296-2e4469c04183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run this to export the manual tagging to the JSON file\n",
    "# with open('manual_tagging.json', 'w') as outfile:\n",
    "#     json.dump(manual_tagging, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1747,
   "id": "c794c275-ffdd-437c-a616-be13df807e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------\n",
      "SSOC 96293 updated successfully!\n",
      "[21687]\n"
     ]
    }
   ],
   "source": [
    "# Add a simple function to prevent accidental override\n",
    "if ssoc in manual_tagging.keys():\n",
    "    resp = input(f\"SSOC {ssoc} is already in the dictionary. Are you sure you want to override? Y or N\")\n",
    "    if resp != 'Y':\n",
    "        raise AssertionError(\"Stop\")\n",
    "        \n",
    "# Input the indices here\n",
    "inputting = [21687]\n",
    "\n",
    "\n",
    "# Deduplicate the indices\n",
    "inputting_dedup = list(set(inputting))\n",
    "inputting_dedup_for_add = copy.deepcopy(inputting_dedup)\n",
    "\n",
    "# Initialise and append the indices to the SSOC\n",
    "manual_tagging[ssoc] = []\n",
    "for key in manual_tagging.keys():\n",
    "    for new_idx in inputting_dedup:\n",
    "        if new_idx in manual_tagging[key]:\n",
    "            print('---------------------------------------------------------------------')\n",
    "            print(f'Duplicate detected for index {new_idx} which has already been marked for SSOC {key} ({len(manual_tagging[key])})')\n",
    "            print(f'Job title for {new_idx}: {extra_info.loc[new_idx, \"title\"]}')\n",
    "            print(f'SSOC title for {key}: {ssoc_job_titles[str(key)]}')\n",
    "            print(f'Job description:')\n",
    "            print(f'{extra_info.loc[new_idx, \"description\"]}')\n",
    "            resp2 = input(f\"Override or not? Y or N\")\n",
    "            if resp2 == 'Y':\n",
    "                print(f'Removed {new_idx} which had been marked for SSOC {key}')\n",
    "                manual_tagging[key].remove(new_idx)\n",
    "            else:\n",
    "                inputting_dedup_for_add.remove(new_idx)\n",
    "                \n",
    "print('---------------------------------------------------------------------')\n",
    "manual_tagging[ssoc].extend(inputting_dedup_for_add)\n",
    "print(f'SSOC {ssoc} updated successfully!')\n",
    "print(manual_tagging[ssoc])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f3081b-fc8a-4484-b6a3-8dd392742ab7",
   "metadata": {},
   "source": [
    "##### Set the SSOC we are looking for here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1748,
   "id": "548a9b34-bd07-45a8-948e-13badf8ef3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['other elementary workers n.e.c.', 'food delivery on foot', 'food delivery on foot']\n"
     ]
    }
   ],
   "source": [
    "ssoc = str(96299)\n",
    "print(ssoc_job_titles[str(ssoc)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1749,
   "id": "49c75736-0d79-43cf-8bbb-7c76ce90401c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Any other job titles to add? food deliver\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['other elementary workers n.e.c.', 'food delivery on foot', 'food delivery on foot', 'food deliver']\n"
     ]
    }
   ],
   "source": [
    "#import copy\n",
    "search_titles = copy.deepcopy(ssoc_job_titles[str(ssoc)])\n",
    "extra = input(\"Any other job titles to add?\")\n",
    "if len(extra) > 0:\n",
    "    search_titles.extend([title.strip() for title in extra.split(',')])\n",
    "#search_titles.extend(['teaching superintendent'])\n",
    "if '' in search_titles:\n",
    "    search_titles.remove('')\n",
    "# search_titles.remove('housekeeper (hotels and other establishments)')\n",
    "# search_titles.remove('car driver')\n",
    "\n",
    "print(search_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1750,
   "id": "75c35ccc-c9b7-4392-835d-09d7300358c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1951, 3586, 7831, 17873, 18673, 27564, 31630, 31637, 41203]\n",
      "1951: Part Time Food Delivery Driver\n",
      "3586: Motor Food Delivery Rider-Freelance with Bonus\n",
      "7831: Product Lead - Food Delivery üçî\n",
      "17873: Food Delivery Driver\n",
      "18673: GrabFood Delivery Partner\n",
      "27564: 3453 -  Delivery Driver [ Frozen Food / Truck / Class 3 / Pioneer ] \n",
      "31630: Food Delivery Riders\n",
      "31637: Food Delivery Riders\n",
      "41203: Class 3 delivery driver [Food importer & distributer / Truck can drive back / Tuas] 9156\n"
     ]
    }
   ],
   "source": [
    "job_titles_idx = find_matching_job_title(extra_info,\n",
    "                                         include = search_titles,\n",
    "                                         exclude = [],\n",
    "                                         exclude_desc = [])\n",
    "\n",
    "# job_titles_idx = extra_info[(extra_info['description'].str.lower().str.contains('hawker|food|restaurant')) &\n",
    "#                              ~extra_info['title'].str.lower().str.contains('factory|cook|dishwasher') &\n",
    "#                              ~extra_info['description'].str.lower().str.contains('classroom|teach|student|child') &\n",
    "#                               (extra_info['title'].str.lower().str.contains('cleaner') | extra_info['title'].str.lower().str.contains('cleaning'))\n",
    "# #                             ~extra_info['description'].str.lower().str.contains('construction')\n",
    "#                             #extra_info['company_name'].str.lower().str.contains('school') ) &\n",
    "# #                             (extra_info['description'].str.lower().str.contains('language') &\n",
    "# #                              extra_info['description'].str.lower().str.contains('school')) &\n",
    "# #                              extra_info['title'].str.lower().str.contains('supervisor') &\n",
    "# #                              extra_info['description'].str.lower().str.contains('admin') &\n",
    "# #                              extra_info['description'].str.lower().str.contains('account') \n",
    "#                              #extra_info['description'].str.lower().str.contains('office') \n",
    "#                             ].index.tolist()\n",
    "\n",
    "print(job_titles_idx)\n",
    "for i, title in extra_info.loc[job_titles_idx, 'title'].iteritems():\n",
    "    print(f\"{i}: {title}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1756,
   "id": "7e6d69df-d7b8-4db0-8ecd-627ce693929a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in job_titles_idx:\n",
    "#     print(i)\n",
    "#     print(extra_info.loc[i, 'company_name'])\n",
    "#     print(extra_info.loc[i, 'title'])\n",
    "#     print(extra_info.loc[i, 'Predicted_SSOC_2020'])\n",
    "#     print(extra_info.loc[i, 'description'])\n",
    "#     print('----------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1755,
   "id": "1004e89d-c691-4722-a333-0b8d42ae6390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ssoc_index = SSOC_2020[SSOC_2020['SSOC 2020'] == int(ssoc)].index[0]\n",
    "# identify_top_n(SSOC_2020_nlp[ssoc_index], data, extra_info, target_vecs, top_n = 50, threshold = 0.80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c16d4f-bfc9-4b8b-a41e-2be5df621dbd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### E) Generating Labelled Dataset\n",
    "\n",
    "Using the manual tagging, we generate the labelled dataset that will be used for the initial training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "316da92d-969a-4702-b014-0049686b2860",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this to initialise the dictionary object\n",
    "with open('manual_tagging.json', 'r') as outfile:\n",
    "    manual_tagging = json.load(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40cbfd6d-2167-4a54-a641-6d4695421e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of labelled SSOCs: 564\n"
     ]
    }
   ],
   "source": [
    "print(f'Total number of labelled SSOCs: {len(manual_tagging.keys())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a57d98a3-24b0-47ae-bfe6-54677978398b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing SSOC 96293...\r"
     ]
    }
   ],
   "source": [
    "tagged_data_list = []\n",
    "\n",
    "for ssoc, mcf_idx in manual_tagging.items():\n",
    "    \n",
    "    print(f'Processing SSOC {ssoc}...\\r', end = '')\n",
    "    \n",
    "    tagged_data = extra_info.loc[mcf_idx, :]\n",
    "    tagged_data['Predicted_SSOC_2020'] = ssoc\n",
    "    \n",
    "    tagged_data_list.append(tagged_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d184b70a-df18-4ee7-a27f-9b82f52ad73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_labelled = pd.concat(tagged_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02bc76a4-1af2-4b64-87db-ed3fe7487e3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14557, 19)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_labelled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94026fd3-d345-4f0b-97d6-d9e4d8c5a4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_labelled.to_csv('Data/Raw/Raw_Labelled.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
